{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reach1 Example: Make HDF5 File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make and HDF5 file for the Reach1 example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our high level structure, we want the following general layout\n",
    "\n",
    "1. Inputs: Use attributes on 'Inputs' for the Input.txt\n",
    "    - BC: \n",
    "        * BC Type: One of [ TDEPDIRCBC, VELDIRCBC, QINBC, RADVELBC, RADORLFSBC, RADFLUXBC ]\n",
    "            - Locations: has attributes 'Num_XFace' and 'Num_YFace'\n",
    "                * XLocs: array of x-face ids (only exists if Num_XFace > 0)\n",
    "                * YLocs: array of y-face ids (only exists if Num_YFace > 0)\n",
    "            - Forcing: has attributes of 'Units'\n",
    "                * Has datasets that are time series. Dataset label is \"X_\" or \"Y_\" + the face id\n",
    "    - Topo: hold topo elevation\n",
    "    - H: holds initial depth values\n",
    "    - Mann: holds Mannings n\n",
    "    - ILocs: locations for time series output\n",
    "        * Locations has attribute of Num_ILoc\n",
    "        * Data set is a list of the locations by node number.\n",
    "2. Outputs: written by MOD_FreeSurf2D during simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the transition to HDF5 file input and output, two changes are made 'Input.txt' specification.\n",
    "\n",
    "1. STARTTIME is converted to decimal days\n",
    "2. ENDTIME is converted to decimal days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOD_FreeSurf 2D input keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMML = \"#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTTIME = \"STARTTIME\"\n",
    "ENDTIME = \"ENDTIME\"\n",
    "SIMNAME = \"SIMNAME\"\n",
    "DATUM = \"DATUM\"\n",
    "DX = \"DX\"\n",
    "DY = \"DY\"\n",
    "NUMROWS = \"NUMROWS\"\n",
    "NUMCOLS = \"NUMCOLS\"\n",
    "OUTINT = \"OUTINT\"\n",
    "FLUID_DT = \"FLUID_DT\"\n",
    "THETA = \"THETA\"\n",
    "HCUTOFF = \"HCUTOFF\"\n",
    "EPSILON = \"EPSILON\"\n",
    "MAXITER = \"MAXITER\"\n",
    "PRECOND = \"PRECOND\"\n",
    "PATHTRAC = \"PATHTRAC\"\n",
    "MAXSTEPS = \"MAXSTEPS\"\n",
    "MINSTEPS = \"MINSTEPS\"\n",
    "MAXCR = \"MAXCR\"\n",
    "G = \"G\"\n",
    "KAPPA = \"KAPPA\"\n",
    "MNWAL = \"MNWAL\"\n",
    "NUK = \"NUK\"\n",
    "RHOW = \"RHOW\"\n",
    "EVIS = \"EVIS\"\n",
    "CENTRALLATITUDE = \"CENTRALLATITUDE\"\n",
    "COROMEGA = \"COROMEGA\"\n",
    "GAMMATX = \"GAMMATX\"\n",
    "UA = \"UA\"\n",
    "GAMMATY = \"GAMMATY\"\n",
    "VA = \"VA\"\n",
    "TDEPDIRCBC = \"TDEPDIRCBC\"\n",
    "TDEPDXVOL = \"TDEPDXVOL\"\n",
    "TDEPDXDEP = \"TDEPDXDEP\"\n",
    "TDEPDYVOL = \"TDEPDYVOL\"\n",
    "TDEPDYDEP = \"TDEPDYDEP\"\n",
    "VELDIRCBC = \"VELDIRCBC\"\n",
    "VELDXVOL = \"VELDXVOL\"\n",
    "VELDXVEL = \"VELDXVEL\"\n",
    "VELDYVOL = \"VELDYVOL\"\n",
    "VELDYVEL = \"VELDYVEL\"\n",
    "QINBC = \"QINBC\"\n",
    "QINXVOL = \"QINXVOL\"\n",
    "QINXFLUX = \"QINXFLUX\"\n",
    "QINYVOL = \"QINYVOL\"\n",
    "QINYFLUX = \"QINYFLUX\"\n",
    "RADVELBC = \"RADVELBC\"\n",
    "RVELXVOL = \"RVELXVOL\"\n",
    "RVELYVOL = \"RVELYVOL\"\n",
    "RADORLFSBC = \"RADORLFSBC\"\n",
    "RORLFSXVOL = \"RORLFSXVOL\"\n",
    "RORLFSYVOL = \"RORLFSYVOL\"\n",
    "RADFLUXBC = \"RADFLUXBC\"\n",
    "RFLUXXFLUX = \"RFLUXXFLUX\"\n",
    "RFLUXYFLUX = \"RFLUXYFLUX\"\n",
    "KEY_WORDS = [ STARTTIME, ENDTIME, SIMNAME, DATUM, DX, DY, NUMROWS, NUMCOLS, OUTINT,\n",
    "              FLUID_DT, THETA, HCUTOFF, EPSILON, MAXITER, PRECOND, PATHTRAC, MAXSTEPS, \n",
    "              MINSTEPS, MAXCR, G, KAPPA, MNWAL, NUK, RHOW, EVIS, CENTRALLATITUDE, \n",
    "              COROMEGA, GAMMATX, UA, GAMMATY, VA, TDEPDIRCBC, TDEPDXVOL, TDEPDXDEP, \n",
    "              TDEPDYVOL, TDEPDYDEP, VELDIRCBC, VELDXVOL, VELDXVEL, VELDYVOL, VELDYVEL,\n",
    "              QINBC, QINXVOL, QINXFLUX, QINYVOL, QINYFLUX, RADVELBC, RVELXVOL, RVELYVOL, \n",
    "              RADORLFSBC, RORLFSXVOL, RORLFSYVOL, RADFLUXBC, RFLUXXFLUX, RFLUXYFLUX ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_ATTRS = []\n",
    "BC_ATTRS = [ TDEPDIRCBC, VELDIRCBC, QINBC, RADVELBC, RADORLFSBC, RADFLUXBC ]\n",
    "WIND_ATTRS = [ \"WINDACT\", GAMMATX, GAMMATY ]\n",
    "GEN_ATTRS = [ STARTTIME, ENDTIME, SIMNAME, DATUM, DX, DY, NUMROWS, NUMCOLS, OUTINT,\n",
    "              FLUID_DT, THETA, HCUTOFF, EPSILON, MAXITER, PRECOND, PATHTRAC, MAXSTEPS, \n",
    "              MINSTEPS, MAXCR, G, KAPPA, MNWAL, NUK, RHOW, EVIS, CENTRALLATITUDE, \n",
    "              COROMEGA, RFLUXXFLUX, RFLUXYFLUX ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INT_ATTS = [ NUMROWS, NUMCOLS, OUTINT, MAXITER, PRECOND, PATHTRAC, MAXSTEPS, MINSTEPS, \n",
    "             TDEPDIRCBC, TDEPDXVOL, TDEPDYVOL, VELDIRCBC, VELDXVOL, VELDYVOL, \n",
    "             QINBC, QINXVOL, QINYVOL, RADVELBC, RVELXVOL, RVELYVOL, RADORLFSBC, \n",
    "             RORLFSXVOL, RORLFSYVOL, RADFLUXBC ]\n",
    "FLT_ATTS = [ STARTTIME, ENDTIME, DATUM, DX, DY, FLUID_DT, THETA, HCUTOFF, EPSILON, MAXCR, \n",
    "              G, KAPPA, MNWAL, NUK, RHOW, EVIS, CENTRALLATITUDE, COROMEGA, GAMMATX, UA, \n",
    "              GAMMATY, VA, TDEPDXDEP, TDEPDYDEP, VELDXVEL, VELDYVEL,\n",
    "              QINXFLUX, QINYFLUX, RFLUXXFLUX, RFLUXYFLUX ]\n",
    "STR_ATTS = [ SIMNAME, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "from IPython.display import display, HTML\n",
    "import datetime as dt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5py.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HFILE = \"Dambreak.h5\"\n",
    "WORK_DIR = r'D:\\Repositories\\MOD_FreeSurf2D\\Examples\\DamBreak'\n",
    "In_File = \"input.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string data type\n",
    "str_dt = h5py.string_dtype(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InFiler = os.path.normpath( os.path.join( WORK_DIR, In_File ) )\n",
    "with open(InFiler, 'r' ) as InF:\n",
    "    AllLines = InF.readlines()\n",
    "# close file\n",
    "NumLines = len( AllLines )\n",
    "NumLines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go through and read the input file and make an input dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "In_Dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tLine in AllLines:\n",
    "    if tLine[0] == COMML:\n",
    "        continue\n",
    "    # check for a keyword\n",
    "    if not \"=\" in tLine:\n",
    "        continue\n",
    "    # now get our index\n",
    "    eqInd = tLine.index(\"=\")\n",
    "    kWord = tLine[:eqInd].strip()\n",
    "    if not kWord in KEY_WORDS:\n",
    "        print(\"Invalid key word %s\" % kWord )\n",
    "        continue\n",
    "    # get our values\n",
    "    valStr = tLine[(eqInd+1):].strip()\n",
    "    # test if the value is a list\n",
    "    if valStr[0] == \"[\":\n",
    "        # then is a list\n",
    "        valSLst = valStr.split()\n",
    "        valList = list()\n",
    "        szL = len( valSLst )\n",
    "        iCnt = 0\n",
    "        for cStrV in valSLst:\n",
    "            if iCnt ==  0:\n",
    "                iCnt += 1\n",
    "                continue\n",
    "            if iCnt == (szL - 1):\n",
    "                iCnt += 1\n",
    "                continue\n",
    "            # otherwise parse\n",
    "            if kWord in INT_ATTS:\n",
    "                curVal = int( cStrV )\n",
    "            elif kWord in FLT_ATTS:\n",
    "                curVal = float( cStrV )\n",
    "            else:\n",
    "                iCnt += 1\n",
    "                continue\n",
    "            # add to our list\n",
    "            valList.append( curVal )\n",
    "            iCnt += 1\n",
    "        # end for\n",
    "        In_Dict[kWord] = valList\n",
    "    else:\n",
    "        # this means that scalar\n",
    "        if kWord in INT_ATTS:\n",
    "            curVal = int( valStr )\n",
    "        elif kWord in FLT_ATTS:\n",
    "            curVal = float( valStr )\n",
    "        else:\n",
    "            curVal = str( valStr )\n",
    "        # add to our list\n",
    "        In_Dict[kWord] = curVal\n",
    "    # end if\n",
    "# end for all lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the conversion for STARTTIME and ENDTIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "In_Dict[STARTTIME] = In_Dict[STARTTIME] / 24.0\n",
    "In_Dict[ENDTIME] = In_Dict[ENDTIME] / 24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'STARTTIME': 0.0,\n",
       " 'ENDTIME': 0.0008083333333333333,\n",
       " 'SIMNAME': 'Dambreak_db3',\n",
       " 'DATUM': -9999.0,\n",
       " 'DX': 0.05,\n",
       " 'DY': 0.125,\n",
       " 'NUMROWS': 171,\n",
       " 'NUMCOLS': 30,\n",
       " 'OUTINT': 1,\n",
       " 'FLUID_DT': 0.103,\n",
       " 'THETA': 0.8,\n",
       " 'HCUTOFF': 1e-05,\n",
       " 'EPSILON': 1e-12,\n",
       " 'MAXITER': 100,\n",
       " 'PRECOND': 2,\n",
       " 'PATHTRAC': 1,\n",
       " 'MAXSTEPS': 1000,\n",
       " 'MINSTEPS': 3,\n",
       " 'MAXCR': 50.0,\n",
       " 'G': 9.8,\n",
       " 'KAPPA': 0.4,\n",
       " 'MNWAL': 0.0,\n",
       " 'NUK': 1e-06,\n",
       " 'RHOW': 1000.0,\n",
       " 'EVIS': 0.0,\n",
       " 'CENTRALLATITUDE': 38.0,\n",
       " 'COROMEGA': 0.0,\n",
       " 'GAMMATX': 0.0,\n",
       " 'UA': 0.0,\n",
       " 'GAMMATY': 0.0,\n",
       " 'VA': 0.0,\n",
       " 'TDEPDIRCBC': 0,\n",
       " 'TDEPDXVOL': [0],\n",
       " 'TDEPDXDEP': [0.0],\n",
       " 'TDEPDYVOL': [0],\n",
       " 'TDEPDYDEP': [0.0],\n",
       " 'VELDIRCBC': 0,\n",
       " 'VELDXVOL': [0],\n",
       " 'VELDXVEL': [0.0],\n",
       " 'VELDYVOL': [0],\n",
       " 'VELDYVEL': [0.0],\n",
       " 'QINBC': 0,\n",
       " 'QINXVOL': [0],\n",
       " 'QINXFLUX': [0.0],\n",
       " 'QINYVOL': [0],\n",
       " 'QINYFLUX': [0.0],\n",
       " 'RADVELBC': 1,\n",
       " 'RVELXVOL': [0],\n",
       " 'RVELYVOL': [5101,\n",
       "  5102,\n",
       "  5103,\n",
       "  5104,\n",
       "  5105,\n",
       "  5106,\n",
       "  5107,\n",
       "  5108,\n",
       "  5109,\n",
       "  5110,\n",
       "  5111,\n",
       "  5112,\n",
       "  5113,\n",
       "  5114,\n",
       "  5115,\n",
       "  5116,\n",
       "  5117,\n",
       "  5118,\n",
       "  5119,\n",
       "  5120,\n",
       "  5121,\n",
       "  5122,\n",
       "  5123,\n",
       "  5124,\n",
       "  5125,\n",
       "  5126,\n",
       "  5127,\n",
       "  5128,\n",
       "  5129,\n",
       "  5130],\n",
       " 'RADORLFSBC': 0,\n",
       " 'RORLFSXVOL': [0],\n",
       " 'RORLFSYVOL': [0],\n",
       " 'RADFLUXBC': 0,\n",
       " 'RFLUXXFLUX': 0.0,\n",
       " 'RFLUXYFLUX': 0.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "In_Dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Other Input Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other files all have the same format and are real values in a NUMCOLS per row with NUMROWS rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read2DFile( NRow, NCol, FPName ):\n",
    "    \"\"\"Read a 2D formatted input file\n",
    "    \n",
    "    Args:\n",
    "        NRow (int): number of rows\n",
    "        NCol (int): number of columns\n",
    "        FPName (str): full filepath and string\n",
    "    \n",
    "    Returns:\n",
    "        np.array(NRow, NCol) with read in values\n",
    "    \"\"\"\n",
    "    retArray = np.zeros( (NRow, NCol), dtype=np.float32 )\n",
    "    cRow = 0\n",
    "    cCol = 0\n",
    "    # read the file\n",
    "    with open( FPName, 'r' ) as InF:\n",
    "        for line in InF:\n",
    "            lList = line.strip().split()\n",
    "            flList = [ float(x) for x in lList ]\n",
    "            lLen = len( flList )\n",
    "            for cVal in flList:\n",
    "                retArray[cRow, cCol] = cVal\n",
    "                cCol += 1\n",
    "                if cCol >= NCol:\n",
    "                    cCol = 0\n",
    "                    cRow += 1\n",
    "                # end if\n",
    "            # end value for\n",
    "        # end line for\n",
    "    # end with block and close file\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topo file first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "InTopo = os.path.normpath( os.path.join( WORK_DIR, \"Topo.txt\" ) )\n",
    "Topo = read2DFile( In_Dict[NUMROWS], In_Dict[NUMCOLS], InTopo )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Topo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100.0, 10.000249, 30.70031)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Topo.max(), Topo.min(), Topo.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Depth file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "InDepth = os.path.normpath( os.path.join( WORK_DIR, \"Depth.txt\" ) )\n",
    "Depth = read2DFile( In_Dict[NUMROWS], In_Dict[NUMCOLS], InDepth )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Depth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14999999, 0.0, 0.044202138)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Depth.max(), Depth.min(), Depth.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Manning's n file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "InMann = os.path.normpath( os.path.join( WORK_DIR, \"Mann.txt\" ) )\n",
    "Mann = read2DFile( In_Dict[NUMROWS], In_Dict[NUMCOLS], InMann )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 30)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mann.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01, 0.01, 0.009999999)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mann.max(), Mann.min(), Mann.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Populate the HDF5 File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDFFile = os.path.normpath( os.path.join( WORK_DIR, HFILE ) )\n",
    "f5 = h5py.File( HDFFile, \"w\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the top level groups or folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_grp = f5.create_group(\"Inputs\")\n",
    "out_grp = f5.create_group(\"Outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ig_ats = in_grp.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Scalars to Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write scalar inputs from Input.txt to attributes of the \"Inputs\" group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tKey in GEN_ATTRS:\n",
    "    if tKey in INT_ATTS:\n",
    "        ig_ats.create( name=tKey, data=In_Dict[tKey], shape=None, dtype=np.int32 )\n",
    "    elif tKey in FLT_ATTS:\n",
    "        ig_ats.create( name=tKey, data=In_Dict[tKey], shape=None, dtype=np.float64 )\n",
    "    elif tKey in STR_ATTS:\n",
    "        ig_ats.create( name=tKey, data=In_Dict[tKey], shape=None, dtype=str_dt )\n",
    "    # end if\n",
    "# end for\n",
    "for tKey in BC_ATTRS:\n",
    "    if tKey in INT_ATTS:\n",
    "        ig_ats.create( name=tKey, data=In_Dict[tKey], shape=None, dtype=np.int32 )\n",
    "    elif tKey in FLT_ATTS:\n",
    "        ig_ats.create( name=tKey, data=In_Dict[tKey], shape=None, dtype=np.float64 )\n",
    "    elif tKey in STR_ATTS:\n",
    "        ig_ats.create( name=tKey, data=In_Dict[tKey], shape=None, dtype=str_dt )\n",
    "    # end if\n",
    "# end for\n",
    "for tKey in WIND_ATTRS:\n",
    "    if tKey == \"WINDACT\":\n",
    "        ig_ats.create( name=tKey, data=0, shape=None, dtype=np.int32 )\n",
    "        continue\n",
    "    # end if\n",
    "    if tKey in INT_ATTS:\n",
    "        ig_ats.create( name=tKey, data=In_Dict[tKey], shape=None, dtype=np.int32 )\n",
    "    elif tKey in FLT_ATTS:\n",
    "        ig_ats.create( name=tKey, data=In_Dict[tKey], shape=None, dtype=np.float64 )\n",
    "    elif tKey in STR_ATTS:\n",
    "        ig_ats.create( name=tKey, data=In_Dict[tKey], shape=None, dtype=str_dt )\n",
    "    # end if\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write BC Forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boundary condition forcing is a time varying input. Only the 'inflow' boundary types can be specified as time varying. These inflow boundary types include the following:\n",
    "1. TDEPDIRCBC: specified water surface elevation\n",
    "2. VELDIRCBC: specified velocity of inflow\n",
    "3. QINBC: specified discharge\n",
    "\n",
    "Radiation boundary conditions are used for domain outflow. Three types are included in **MOD_FreeSurf2D**.\n",
    "1. RADVELBC\n",
    "2. RADORLFSBC\n",
    "3. RADFLUXBC\n",
    "\n",
    "Radiation BCs are calculated internally and only the locations require specification. The *RADFLUXBC* type only requieres specification of the total discharge across all of these boundaries by X- or Y-face. Consequently, the *RFLUXXFLUX* and *RFLUXYFLUX* specifications are stored with the other scalars as attributes on the \"Inputs\" group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "InBCs = BC_ATTRS[:3]\n",
    "OutBCs = BC_ATTRS[3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Input.txt file does not allow a time series to be specified for forcing. Create a synthetic time series from the Input.txt file specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00016166666666666668"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumInts = 4\n",
    "tsDT = ( In_Dict[ENDTIME] - In_Dict[STARTTIME] ) / float( NumInts + 1 )\n",
    "tsDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0,\n",
       "  0.00016166666666666668,\n",
       "  0.00032333333333333335,\n",
       "  0.000485,\n",
       "  0.0006466666666666667,\n",
       "  0.0008083333333333334],\n",
       " array([0.        , 0.00016167, 0.00032333, 0.000485  , 0.00064667,\n",
       "        0.00080833], dtype=float32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsList = [ In_Dict[STARTTIME] + ( x * tsDT ) for x in range(0, NumInts + 2) ]\n",
    "nptsList = np.array( tsList, dtype=np.float32 )\n",
    "tsList, nptsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumTimeInts = len( tsList )\n",
    "NumTimeInts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the inflow BCs first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_grp = in_grp.create_group(\"BC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cBC in InBCs:\n",
    "    if In_Dict[cBC] != 1:\n",
    "        # then skip\n",
    "        continue\n",
    "    # now populate the file structure\n",
    "    cbc_grp = bc_grp.create_group(cBC)\n",
    "    cbc_locs = cbc_grp.create_group(\"Locations\")\n",
    "    cbc_forc = cbc_grp.create_group(\"Forcing\")\n",
    "    # now need to know which BC type are working with\n",
    "    if cBC == TDEPDIRCBC:\n",
    "        XFaces = In_Dict[TDEPDXVOL]\n",
    "        if XFaces[0] == 0:\n",
    "            XFaces = list()\n",
    "        NumXFace = len(XFaces)\n",
    "        YFaces = In_Dict[TDEPDYVOL]\n",
    "        if YFaces[0] == 0:\n",
    "            YFaces = list()\n",
    "        NumYFace = len(YFaces)\n",
    "        if NumXFace > 0:\n",
    "            XForcingA = In_Dict[TDEPDXDEP]\n",
    "        if NumYFace > 0:\n",
    "            YForcingA = In_Dict[TDEPDYDEP]\n",
    "        # \n",
    "        unitsStr = \"m\"\n",
    "    elif cBC == VELDIRCBC:\n",
    "        XFaces = In_Dict[VELDXVOL]\n",
    "        if XFaces[0] == 0:\n",
    "            XFaces = list()\n",
    "        NumXFace = len(XFaces)\n",
    "        YFaces = In_Dict[VELDYVOL]\n",
    "        if YFaces[0] == 0:\n",
    "            YFaces = list()\n",
    "        NumYFace = len(YFaces)\n",
    "        if NumXFace > 0:\n",
    "            XForcingA = In_Dict[VELDXVEL]\n",
    "        if NumYFace > 0:\n",
    "            YForcingA = In_Dict[VELDYVEL]\n",
    "        # \n",
    "        unitsStr = \"m/s\"\n",
    "    elif cBC == QINBC:\n",
    "        XFaces = In_Dict[QINXVOL]\n",
    "        if XFaces[0] == 0:\n",
    "            XFaces = list()\n",
    "        NumXFace = len(XFaces)\n",
    "        YFaces = In_Dict[QINYVOL]\n",
    "        if YFaces[0] == 0:\n",
    "            YFaces = list()\n",
    "        NumYFace = len(YFaces)\n",
    "        if NumXFace > 0:\n",
    "            XForcingA = In_Dict[QINXFLUX]\n",
    "        if NumYFace > 0:\n",
    "            YForcingA = In_Dict[QINYFLUX]\n",
    "        # \n",
    "        unitsStr = \"m2/s\"\n",
    "    # end if\n",
    "    # now write out\n",
    "    loc_attrs = cbc_locs.attrs\n",
    "    loc_attrs.create( name=\"Num_XFace\", data=NumXFace, shape=None, dtype=np.int32 )\n",
    "    loc_attrs.create( name=\"Num_YFace\", data=NumYFace, shape=None, dtype=np.int32 )\n",
    "    forc_attrs = cbc_forc.attrs\n",
    "    forc_attrs.create( name=\"Units\", data=unitsStr, shape=None, dtype=str_dt )\n",
    "    if NumXFace > 0:\n",
    "        npXLocs = np.array( XFaces, dtype=np.int32 )\n",
    "        cbc_locs.create_dataset(\"XLocs\", data=npXLocs )\n",
    "        xCnt = 0\n",
    "        for cLoc in XFaces:\n",
    "            dsName = \"X_%d\" % cLoc\n",
    "            npVals = XForcingA[xCnt] * np.ones( NumTimeInts, dtype=np.float32 )\n",
    "            bc2dts = np.vstack((nptsList, npVals)).T\n",
    "            cbc_forc.create_dataset(dsName, data=bc2dts)\n",
    "            xCnt += 1\n",
    "        # end for\n",
    "    # end if\n",
    "    if NumYFace > 0:\n",
    "        npYLocs = np.array( YFaces, dtype=np.int32 )\n",
    "        cbc_locs.create_dataset(\"YLocs\", data=npYLocs )\n",
    "        yCnt = 0\n",
    "        for cLoc in YFaces:\n",
    "            dsName = \"Y_%d\" % cLoc\n",
    "            npVals = YForcingA[yCnt] * np.ones( NumTimeInts, dtype=np.float32 )\n",
    "            bc2dts = np.vstack((nptsList, npVals)).T\n",
    "            cbc_forc.create_dataset(dsName, data=bc2dts)\n",
    "            yCnt += 1\n",
    "        # end for\n",
    "    # end if\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outflow BCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cBC in OutBCs:\n",
    "    if In_Dict[cBC] != 1:\n",
    "        # then skip\n",
    "        continue\n",
    "    # two different types of input.\n",
    "    if cBC == RADFLUXBC:\n",
    "        # then input is scalar so just use the attributes on \n",
    "        #  inputs\n",
    "        continue\n",
    "    # now populate the file structure\n",
    "    cbc_grp = bc_grp.create_group(cBC)\n",
    "    cbc_locs = cbc_grp.create_group(\"Locations\")\n",
    "    # only need to write out the face locations\n",
    "    if cBC == RADVELBC:\n",
    "        XFaces = In_Dict[RVELXVOL]\n",
    "        if XFaces[0] == 0:\n",
    "            XFaces = list()\n",
    "        NumXFace = len(XFaces)\n",
    "        YFaces = In_Dict[RVELYVOL]\n",
    "        if YFaces[0] == 0:\n",
    "            YFaces = list()\n",
    "        NumYFace = len(YFaces)\n",
    "    elif cBC == RADORLFSBC:\n",
    "        XFaces = In_Dict[RORLFSXVOL]\n",
    "        if XFaces[0] == 0:\n",
    "            XFaces = list()\n",
    "        NumXFace = len(XFaces)\n",
    "        YFaces = In_Dict[RORLFSYVOL]\n",
    "        if YFaces[0] == 0:\n",
    "            YFaces = list()\n",
    "        NumYFace = len(YFaces)\n",
    "    # now write out\n",
    "    loc_attrs = cbc_locs.attrs\n",
    "    loc_attrs.create( name=\"Num_XFace\", data=NumXFace, shape=None, dtype=np.int32 )\n",
    "    loc_attrs.create( name=\"Num_YFace\", data=NumYFace, shape=None, dtype=np.int32 )\n",
    "    if NumXFace > 0:\n",
    "        npXLocs = np.array( XFaces, dtype=np.int32 )\n",
    "        cbc_locs.create_dataset(\"XLocs\", data=npXLocs )\n",
    "    # end if\n",
    "    if NumYFace > 0:\n",
    "        npYLocs = np.array( YFaces, dtype=np.int32 )\n",
    "        cbc_locs.create_dataset(\"YLocs\", data=npYLocs )\n",
    "    # end if\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Paramters and Initial Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topography, initial depth, and Manning's n are the arrays that need to be written to HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"Mann\": shape (171, 30), type \"<f4\">"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_grp.create_dataset(\"Topo\", data=Topo)\n",
    "in_grp.create_dataset(\"H\", data=Depth)\n",
    "in_grp.create_dataset(\"Mann\", data=Mann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the ILocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ILocs are individual locations where velocity and stage are output for each simulation time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "NodeLocs = [ 5, 46, 1095, 1096, 1125, 1126, 2047, 2048, 2077, 2078, 2649, 2679,\n",
    "             3253, 3283, 3855, 3856, 3885, 3886, 4455, 4456, 4485, 4486 ]\n",
    "npNodes = np.array( NodeLocs, dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumILoc = len( NodeLocs )\n",
    "NumILoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "iloc_grp = in_grp.create_group(\"ILocs\")\n",
    "iloc_attrs = iloc_grp.attrs\n",
    "iloc_attrs.create( name=\"Num_ILoc\", data=NumILoc, shape=None, dtype=np.int32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"ILocList\": shape (22,), type \"<i4\">"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iloc_grp.create_dataset(\"ILocList\", data=npNodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Close the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
